---
name: activation function
route: /activation- function
order: 1
---

# activation function (Ham kich hoat)
A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.
